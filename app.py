import streamlit as st
import pandas as pd
import requests

# Configuration de la page en mode "wide"
st.set_page_config(page_title="Comparateur de Communes", layout="wide")

# Chargement des donnÃ©es depuis le CSV avec mise en cache
@st.cache_data
def load_data():
    df = pd.read_csv("communes_synthetique.csv")
    return df

# RequÃªte SPARQL : rÃ©cupÃ©rer l'URL de l'article WikipÃ©dia correspondant Ã  un code INSEE
@st.cache_data
def get_wikipedia_title_from_insee(insee_code):
    query = f"""
    SELECT ?article WHERE {{
      ?ville wdt:P374 "{insee_code}".
      ?article schema:about ?ville;
               schema:inLanguage "fr";
               schema:isPartOf <https://fr.wikipedia.org/>.
    }}
    """
    url = "https://query.wikidata.org/sparql"
    headers = {"Accept": "application/sparql-results+json"}
    response = requests.get(url, params={'query': query, 'format': 'json'}, headers=headers)
    if response.status_code != 200:
        return None
    data = response.json()
    results = data.get("results", {}).get("bindings", [])
    if results:
        full_url = results[0]["article"]["value"]
        # Extraction du titre Ã  partir de l'URL (la partie aprÃ¨s "/wiki/")
        title = full_url.split("/wiki/")[-1]
        return title
    return None

# RÃ©cupÃ©ration de l'image via l'API REST de WikipÃ©dia
@st.cache_data
def get_wikipedia_thumbnail(title):
    url = f"https://fr.wikipedia.org/api/rest_v1/page/summary/{title}"
    response = requests.get(url)
    if response.status_code == 200:
        data = response.json()
        image_url = data.get("thumbnail", {}).get("source", None)
        city_name = data.get("title", None)
        extract = data.get("extract", None)
        return image_url, city_name, extract
    return None, None, None

# ğŸŒ¦ï¸ RÃ©cupÃ©ration de la mÃ©tÃ©o prÃ©visionnelle
@st.cache_data
def get_weather_forecast(insee_code):
    import requests

    TOKEN = "53ed6fa76d3c503a4d2577a7d14909104244f231fdf3fc9cbd639b146073801b"
    url = f"https://api.meteo-concept.com/api/forecast/daily?token={TOKEN}&insee={insee_code}"

    weather_codes = {0: "Soleil", 1: "Peu nuageux", 2: "Ciel voilÃ©", 3: "Nuageux", 4: "TrÃ¨s nuageux", 5: "Couvert",6: "Brouillard", 7: "Brouillard givrant", 10: "Pluie faible", 11: "Pluie modÃ©rÃ©e", 12: "Pluie forte",13: "Pluie faible verglaÃ§ante", 14: "Pluie modÃ©rÃ©e verglaÃ§ante", 15: "Pluie forte verglaÃ§ante",16: "Bruine", 20: "Neige faible", 21: "Neige modÃ©rÃ©e", 22: "Neige forte",
    30: "Pluie et neige mÃªlÃ©es faibles", 31: "Pluie et neige mÃªlÃ©es modÃ©rÃ©es", 32: "Pluie et neige mÃªlÃ©es fortes",40: "Averses de pluie locales et faibles", 41: "Averses de pluie locales", 42: "Averses locales et fortes",43: "Averses de pluie faibles", 44: "Averses de pluie", 45: "Averses de pluie fortes",46: "Averses de pluie faibles et frÃ©quentes", 47: "Averses de pluie frÃ©quentes", 48: "Averses de pluie fortes et frÃ©quentes",60: "Averses de neige localisÃ©es et faibles", 61: "Averses de neige localisÃ©es", 62: "Averses de neige localisÃ©es et fortes",63: "Averses de neige faibles", 64: "Averses de neige", 65: "Averses de neige fortes",66: "Averses de neige faibles et frÃ©quentes", 67: "Averses de neige frÃ©quentes", 68: "Averses de neige fortes et frÃ©quentes",
    70: "Averses de pluie et neige mÃªlÃ©es localisÃ©es et faibles", 71: "Averses de pluie et neige mÃªlÃ©es localisÃ©es",72: "Averses de pluie et neige mÃªlÃ©es localisÃ©es et fortes", 73: "Averses de pluie et neige mÃªlÃ©es faibles",74: "Averses de pluie et neige mÃªlÃ©es", 75: "Averses de pluie et neige mÃªlÃ©es fortes",76: "Averses de pluie et neige mÃªlÃ©es faibles et nombreuses", 77: "Averses de pluie et neige mÃªlÃ©es frÃ©quentes",78: "Averses de pluie et neige mÃªlÃ©es fortes et frÃ©quentes",
    100: "Orages faibles et locaux", 101: "Orages locaux", 102: "Orages forts et locaux",103: "Orages faibles", 104: "Orages", 105: "Orages forts", 106: "Orages faibles et frÃ©quents",107: "Orages frÃ©quents", 108: "Orages forts et frÃ©quents",120: "Orages faibles et locaux de neige ou grÃ©sil", 121: "Orages locaux de neige ou grÃ©sil",
    122: "Orages modÃ©rÃ©s de neige ou grÃ©sil", 123: "Orages faibles de neige ou grÃ©sil",124: "Orages de neige ou grÃ©sil", 125: "Orages forts de neige ou grÃ©sil",126: "Orages faibles et frÃ©quents de neige ou grÃ©sil", 127: "Orages frÃ©quents de neige ou grÃ©sil",128: "Orages forts et frÃ©quents de neige ou grÃ©sil",
    130: "Orages faibles et locaux de pluie et neige mÃªlÃ©es ou grÃ©sil",131: "Orages locaux de pluie et neige mÃªlÃ©es ou grÃ©sil",132: "Orages forts et locaux de pluie et neige mÃªlÃ©es ou grÃ©sil",133: "Orages faibles de pluie et neige mÃªlÃ©es ou grÃ©sil",
    134: "Orages de pluie et neige mÃªlÃ©es ou grÃ©sil",135: "Orages forts de pluie et neige mÃªlÃ©es ou grÃ©sil",136: "Orages faibles et frÃ©quents de pluie et neige mÃªlÃ©es ou grÃ©sil",137: "Orages frÃ©quents de pluie et neige mÃªlÃ©es ou grÃ©sil",138: "Orages forts et frÃ©quents de pluie et neige mÃªlÃ©es ou grÃ©sil",140: "Pluies orageuses", 141: "Pluie et neige mÃªlÃ©es Ã  caractÃ¨re orageux", 142: "Neige Ã  caractÃ¨re orageux",
    210: "Pluie faible intermittente", 211: "Pluie modÃ©rÃ©e intermittente", 212: "Pluie forte intermittente",220: "Neige faible intermittente", 221: "Neige modÃ©rÃ©e intermittente", 222: "Neige forte intermittente",230: "Pluie et neige mÃªlÃ©es", 231: "Pluie et neige mÃªlÃ©es", 232: "Pluie et neige mÃªlÃ©es",235: "Averses de grÃªle"
}

    response = requests.get(url)
    if response.status_code == 200:
        data = response.json()
        forecasts = []
        for item in data['forecast'][:4]:  # Prochains 4 jours
            forecasts.append({
                "date": item['datetime'][:10],
                "weather": weather_codes.get(item['weather'], f"Code {item['weather']}"),
                "tmin": item['tmin'],
                "tmax": item['tmax'],
                "wind": item['wind10m'],
                "sun_hours": item['sun_hours']
            })
        return forecasts
    else:
        return None


# Fonction pour rÃ©cupÃ©rer les normales climatiques d'une commune
@st.cache_data
def get_climate_data(latitude, longitude):
    import http.client
    import json

    conn = http.client.HTTPSConnection("meteostat.p.rapidapi.com")
    headers = {
        'x-rapidapi-key': "d86ec0ac76msh7329992dd8cf6c5p189bcfjsn4291599cfb32",
        'x-rapidapi-host': "meteostat.p.rapidapi.com"
    }

    # Trouver les stations proches
    nearby_endpoint = f"/stations/nearby?lat={latitude}&lon={longitude}"
    conn.request("GET", nearby_endpoint, headers=headers)
    res = conn.getresponse()
    nearby_data = res.read()

    stations_info = json.loads(nearby_data.decode("utf-8"))
    stations_list = stations_info.get("data", [])

    for station in stations_list:
        station_id = station["id"]

        normals_endpoint = f"/stations/normals?station={station_id}&start=1981&end=2010"
        conn.request("GET", normals_endpoint, headers=headers)
        res = conn.getresponse()
        climate_data = res.read()

        try:
            climate_info = json.loads(climate_data.decode("utf-8"))
            if "data" in climate_info and climate_info["data"]:
                data = climate_info["data"]

                # Calculs
                def safe_avg(months):
                    valid = [x for x in months if x is not None]
                    return round(sum(valid) / len(valid), 2) if valid else None

                hiver = [data[11]["tavg"], data[0]["tavg"], data[1]["tavg"]]
                printemps = [data[2]["tavg"], data[3]["tavg"], data[4]["tavg"]]
                ete = [data[5]["tavg"], data[6]["tavg"], data[7]["tavg"]]
                automne = [data[8]["tavg"], data[9]["tavg"], data[10]["tavg"]]

                moy_hiver = safe_avg(hiver)
                moy_printemps = safe_avg(printemps)
                moy_ete = safe_avg(ete)
                moy_automne = safe_avg(automne)

                prcp_mensuelles = [m["prcp"] for m in data if m["prcp"] is not None]
                moy_prcp = round(sum(prcp_mensuelles) / len(prcp_mensuelles), 2) if prcp_mensuelles else None

                tsun_mensuel = [m["tsun"] for m in data if m["tsun"] is not None]
                moy_tsun = round(sum(tsun_mensuel) / len(tsun_mensuel), 2) if tsun_mensuel else None

                return {
                    "hiver": moy_hiver,
                    "printemps": moy_printemps,
                    "ete": moy_ete,
                    "automne": moy_automne,
                    "prcp": moy_prcp,
                    "tsun": moy_tsun
                }
        except:
            continue

    return None  # Si aucune station avec data


# Chargement du DataFrame
df = load_data()

# VÃ©rification de la prÃ©sence de la colonne contenant le nom de la commune
if "nom_standard" not in df.columns:
    st.error("La colonne 'nom_standard' n'est pas prÃ©sente dans le DataFrame.")
else:
    # Trier les noms de communes en ordre alphabÃ©tique pour faciliter leur recherche dans la selectbox
    communes = sorted(df["nom_standard"].unique())

    st.title("Comparateur de Communes")
    st.markdown("SÃ©lectionnez une commune Ã  gauche et une Ã  droite pour comparer leurs informations et images.")

    # SÃ©lection des communes dans deux colonnes (selectbox intÃ©grÃ©e avec saisie possible pour filtrer)
    col_select_left, col_select_right = st.columns(2)
    with col_select_left:
        commune_gauche = st.selectbox("Commune de gauche", communes, key="commune_gauche")
    with col_select_right:
        commune_droite = st.selectbox("Commune de droite", communes, key="commune_droite")

    st.markdown("---")

    # Affichage des informations et images dans deux colonnes
    col_detail_left, col_detail_right = st.columns(2)

    # DÃ©tails pour la commune de gauche
    with col_detail_left:
        st.header(f"DÃ©tails de {commune_gauche}")
        details_gauche = df[df["nom_standard"] == commune_gauche]
        if not details_gauche.empty:
            row = details_gauche.iloc[0]
            # Affichage de chaque information issue du CSV
            for col_name in details_gauche.columns:
                st.markdown(f"**{col_name}** : {row[col_name]}")
            # RÃ©cupÃ©rer et afficher l'image via WikipÃ©dia Ã  partir du code INSEE
            code_insee_left = row["code_insee"]
            if code_insee_left:
                with st.spinner("Recherche de l'image..."):
                    title_wiki = get_wikipedia_title_from_insee(code_insee_left)
                    if title_wiki:
                        image_url, city_name, _ = get_wikipedia_thumbnail(title_wiki)
                        if image_url:
                            st.image(image_url, caption=city_name, width=400)
                        else:
                            st.warning("Aucune image trouvÃ©e pour cette commune.")
                    else:
                        st.error("Aucune page WikipÃ©dia trouvÃ©e pour ce code INSEE.")
        else:
            st.write("Aucune donnÃ©e disponible.")

        # RÃ©cupÃ©ration mÃ©tÃ©o
        with st.spinner("Recherche de la mÃ©tÃ©o..."):
            forecast_left = get_weather_forecast(code_insee_left)
            if forecast_left:
                st.subheader("PrÃ©visions mÃ©tÃ©o (prochains jours)")
                for day in forecast_left:
                    st.write(f"ğŸ“… {day['date']}")
                    st.write(f"ğŸŒ¦ï¸ {day['weather']}")
                    st.write(f"ğŸŒ¡ï¸ {day['tmin']}Â°C â†’ {day['tmax']}Â°C")
                    st.write(f"ğŸŒ¬ï¸ Vent moyen : {day['wind']} km/h")
                    st.write(f"â˜€ï¸ Ensoleillement : {day['sun_hours']} h")
                    st.markdown("---")
            else:
                st.warning("Pas de donnÃ©es mÃ©tÃ©o disponibles.")

        # RÃ©cupÃ©ration climat
        latitude_left = row["latitude_centre"]
        longitude_left = row["longitude_centre"]

        if pd.notna(latitude_left) and pd.notna(longitude_left):
            with st.spinner("Recherche du climat..."):
                climat_left = get_climate_data(latitude_left, longitude_left)
                if climat_left:
                    st.subheader("Climat (1981â€“2010)")
                    st.write(f"ğŸŒ¡ï¸ Hiver : {climat_left['hiver']} Â°C")
                    st.write(f"ğŸŒ¡ï¸ Printemps : {climat_left['printemps']} Â°C")
                    st.write(f"ğŸŒ¡ï¸ Ã‰tÃ© : {climat_left['ete']} Â°C")
                    st.write(f"ğŸŒ¡ï¸ Automne : {climat_left['automne']} Â°C")
                    st.write(f"ğŸŒ§ï¸ PrÃ©cipitations moyennes : {climat_left['prcp']} mm/mois")
                    st.write(f"ğŸŒ¤ï¸ Ensoleillement moyen : {round(climat_left['tsun']/60, 1)} h/jour")
                else:
                    st.warning("Pas de donnÃ©es climatiques disponibles.")


    # DÃ©tails pour la commune de droite
    with col_detail_right:
        st.header(f"DÃ©tails de {commune_droite}")
        details_droite = df[df["nom_standard"] == commune_droite]
        if not details_droite.empty:
            row = details_droite.iloc[0]
            for col_name in details_droite.columns:
                st.markdown(f"**{col_name}** : {row[col_name]}")
            code_insee_right = row["code_insee"]
            if code_insee_right:
                with st.spinner("Recherche de l'image..."):
                    title_wiki = get_wikipedia_title_from_insee(code_insee_right)
                    if title_wiki:
                        image_url, city_name, _ = get_wikipedia_thumbnail(title_wiki)
                        if image_url:
                            st.image(image_url, caption=city_name, width=400)
                        else:
                            st.warning("Aucune image trouvÃ©e pour cette commune.")
                    else:
                        st.error("Aucune page WikipÃ©dia trouvÃ©e pour ce code INSEE.")
        else:
            st.write("Aucune donnÃ©e disponible.")
        # RÃ©cupÃ©ration mÃ©tÃ©o
        with st.spinner("Recherche de la mÃ©tÃ©o..."):
            forecast_left = get_weather_forecast(code_insee_left)
            if forecast_left:
                st.subheader("PrÃ©visions mÃ©tÃ©o (prochains jours)")
                for day in forecast_left:
                    st.write(f"ğŸ“… {day['date']}")
                    st.write(f"ğŸŒ¦ï¸ {day['weather']}")
                    st.write(f"ğŸŒ¡ï¸ {day['tmin']}Â°C â†’ {day['tmax']}Â°C")
                    st.write(f"ğŸŒ¬ï¸ Vent moyen : {day['wind']} km/h")
                    st.write(f"â˜€ï¸ Ensoleillement : {day['sun_hours']} h")
                    st.markdown("---")
            else:
                st.warning("Pas de donnÃ©es mÃ©tÃ©o disponibles.")

        # RÃ©cupÃ©ration climat
        latitude_left = row["latitude_centre"]
        longitude_left = row["longitude_centre"]

        if pd.notna(latitude_left) and pd.notna(longitude_left):
            with st.spinner("Recherche du climat..."):
                climat_left = get_climate_data(latitude_left, longitude_left)
                if climat_left:
                    st.subheader("Climat (1981â€“2010)")
                    st.write(f"ğŸŒ¡ï¸ Hiver : {climat_left['hiver']} Â°C")
                    st.write(f"ğŸŒ¡ï¸ Printemps : {climat_left['printemps']} Â°C")
                    st.write(f"ğŸŒ¡ï¸ Ã‰tÃ© : {climat_left['ete']} Â°C")
                    st.write(f"ğŸŒ¡ï¸ Automne : {climat_left['automne']} Â°C")
                    st.write(f"ğŸŒ§ï¸ PrÃ©cipitations moyennes : {climat_left['prcp']} mm/mois")
                    st.write(f"ğŸŒ¤ï¸ Ensoleillement moyen : {round(climat_left['tsun']/60, 1)} h/jour")
                else:
                    st.warning("Pas de donnÃ©es climatiques disponibles.")
